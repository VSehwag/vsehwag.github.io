<!DOCTYPE html>

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-178038666-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag("js", new Date());

    gtag("config", "UA-178038666-1");
  </script>

  <title>Vikash Sehwag - Academic webpage</title>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="preconnect" href="https://fonts.googleapis.com" />
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  <link
    href="https://fonts.googleapis.com/css2?family=Nunito:ital,wght@0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap"
    rel="stylesheet" />
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css"
    integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous" />
  <script src="./css/jquery-3.5.1.min.js"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js"
    integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy"
    crossorigin="anonymous"></script>
  <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css" />
  <script src="https://kit.fontawesome.com/b939870cfb.js" crossorigin="anonymous"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <link rel="shortcut icon" href="./images/favicon.ico" />
  <script src="./css/main.js"></script>
  <link rel="stylesheet" href="./css/main.css" />
</head>

<body>
  <nav class="navbar fixed-top navbar-expand-md">
    <div class="container">
      <a class="navbar-brand" href="#"> Vikash Sehwag </a>
      <button class="navbar-toggler navbar-light" type="button" data-toggle="collapse" data-target="#main-navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="main-navigation">
        <ul class="navbar-nav">
          <li class="nav-item">
            <a class="nav-link" href="#pubs">Publications</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="#teaching">Teaching</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="./docs/vikash_sehwag_cv.pdf" target="_blank">Resume</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="https://vsehwag.github.io/blog">Blog</a>
          </li>
        </ul>
      </div>
    </div>
  </nav>

  <div class="full-project-divider top-divider"></div>

  <!-- Biography: first section of webpage -->
  <div class="bio container" id="aboutme">
    <div class="box profile">
      <div class="headshot">
        <img src="./images/headshot.jpg" alt="Udari Madhushani" />
      </div>
      <h2 class="name section-heading"></h2>
      <h3 class="affil">PhD Candidate, Princeton University</h3>
      <h3 class="email">vvikash [at] princeton [dot] edu</h3>
    </div>
    <div class="box about-me">
      <p>
        I am a PhD candidate in Electrical Engineering at
        <a href="https://www.princeton.edu/" target="_blank">Princeton University</a>.
        <em>I build trustworthy machine learning systems, especially using
          generative models.</em>
      </p>
      <!-- <p>
        I am interested in research
        problems at the intersection of
        <em>security, privacy, and machine learning</em>. Some topics I have
        worked on are adversarial robust supervised / self-supervised learning,
        adversarial robustness in compressed neural networks, self-supervised
        detection of outliers, robust open-world machine learning, and privacy
        leakage in large scale deep learning.
      </p> -->
      <p>
        I am advised by
        <a href="https://www.princeton.edu/~pmittal/">Prateek Mittal</a> and
        <a href="https://www.princeton.edu/~chiangm/">Mung Chiang</a>. Before
        coming to Princeton, I completed my undergraduate at IIT Kharagpur, India. I have
        previously interned at
        <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-redmond/" target="_blank">Microsoft
          Research</a>
        and <a href="https://ai.facebook.com/" target="_blank">Meta AI</a>. I
        have also been fortunate to receive
        <a href="https://www.qualcomm.com/invention/research/university-relations/innovation-fellowship/winners"
          target="_blank">Qualcomm Innovation Fellowship</a>.
        <!-- 
        Before
        joining Princeton, I completed my undergraduate in E&ECE (with minor in
        CS) from <a href="http://www.iitkgp.ac.in/">IIT Kharagpur</a>, India. I
        earlier had an amazing summer internship experience at
        <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-redmond/" target="_blank">Microsoft
          Research</a>, Redmond. Before that, I spent a wonderful summer working with
        <a href="https://www.bcs.tu-darmstadt.de/biocomm/people_1/professor/heinzkoeppl.en.jsp" target="_blank">Heinz
          Koeppl</a>
        at
        <a href="https://www.tu-darmstadt.de/" target="_blank">TU Darmstadt</a>.
        I have also been fortunate to receive
        <a href="https://www.qualcomm.com/invention/research/university-relations/innovation-fellowship/winners"
          target="_blank">Qualcomm Innovation Fellowship</a>
        in 2019. -->
      </p>
      <p>
        <strong>Major update</strong>: I am leading the organization of virtual
        <a href="https://vsehwag.github.io/SPML_seminar/" target="_blank">seminar series on Security & Privacy in
          Machine Learning (SPML)</a>.
      </p>

      <p>I am <strong>on the job market</strong> looking for research-scientist/post-doc positions.</p>
      <ul>
        <li>
          <a href="https://scholar.google.com/citations?user=JAkeEG8AAAAJ&hl=en" target="_blank"><i
              class="ai ai-google-scholar"></i></a>
        </li>
        <li>
          <a href="https://dblp.org/pid/187/5613.html" target="_blank"><i class="ai ai-dblp"></i></a>
        </li>
        <li>
          <a href="https://www.linkedin.com/in/vikash-sehwag/" target="_blank"><i class="fab fa-linkedin"></i></a>
        </li>
        <li>
          <a href="https://twitter.com/VSehwag_" target="_blank"><i class="fab fa-twitter"></i></a>
        </li>
        <li>
          <a href="https://github.com/VSehwag" target="_blank"><i class="fab fa-github"></i></a>
        </li>
      </ul>
    </div>
  </div>

  <div class="project-divider">
    <hr />
  </div>

  <!-- REPLACE THE TWEET SECTION WITH UPCOMING TALKS. -->

  <!-- News: Second section of the webpage-->
  <div class="news container">
    <div class="news-mini-container">
      <div class="news-grid">
        <p class="section-heading">News</p>
        <div class="flex-container">
          <div>02/2023</div>
          <div class="news-text">
            New paper on extracting training data from diffusion models (<a
              href="https://arxiv.org/abs/2301.13188">pdf</a>)
          </div>
        </div>
        <div class="flex-container">
          <div>12/2022</div>
          <div class="news-text">
            Presented <a href="https://arxiv.org/abs/2206.09868">our paper</a> on understanding robust representations
            at Neurips'22.
          </div>
        </div>
        <div class="flex-container">
          <div>09/2022</div>
          <div class="news-text">
            Awarded graduate student award for excellence in service (ECE, Princeton University).
          </div>
        </div>
        <div class="flex-container">
          <div>04/2022</div>
          <div class="news-text">
            Awarded <a
              href="https://ece.princeton.edu/news/honorific-fellowships-fund-research-quantum-sensors-and-trustworthy-ai"
              target="_blank">Charlotte Elizabeth Proctor Honorific Fellowship</a>, one of the highest honors at
            Princeton University.
          </div>
        </div>
        <div class="flex-container">
          <div>03/2022</div>
          <div class="news-text">
            Paper on low-density sampling from diffusion models got accepted at
            <a href="https://arxiv.org/abs/2203.17260" target="_blank">CVPR'22</a>.
          </div>
        </div>
        <div class="flex-container">
          <div>01/2022</div>
          <div class="news-text">
            Paper on using synthetic data in robust learning got accepted at
            <a href="https://arxiv.org/abs/2104.09425" target="_blank">ICLR'22</a>.
          </div>
        </div>
        <div class="flex-container">
          <div>08/2021</div>
          <div class="news-text">
            Finished an amazing research internship at
            <a href="https://ai.facebook.com/">Facebook AI</a>.
          </div>
        </div>
        <div class="flex-container">
          <div>05/2021</div>
          <div class="news-text">
            Paper on lower bounds on adversarial robustness accepted at
            <a href="https://icml.cc/">ICML 2021 </a> (<a href="https://arxiv.org/pdf/2104.08382.pdf">pdf</a>).
          </div>
        </div>
        <div class="flex-container">
          <div>04/2021</div>
          <div class="news-text">
            Paper on improving robustness using proxy distributions is now out
            (<a href="https://arxiv.org/abs/2104.09425">pdf</a>)!
          </div>
        </div>

        <div class="flex-container">
          <div>03/2021</div>
          <div class="news-text">
            <a href="https://robustbench.github.io/">RobustBench</a> won best
            paper honorable mention prize at
            <a href="https://aisecure-workshop.github.io/aml-iclr2021/cfp">ICLR AiSecure</a>
            workshop.
          </div>
        </div>
        <div class="flex-container">
          <div>01/2021</div>
          <div class="news-text">
            Self-supervised outlier detection (SSD) paper accepted at
            <a href="https://iclr.cc/Conferences/2021/Dates" target="_blank">ICLR 2021</a>
            (<a href="https://openreview.net/pdf?id=v5gjXpmR8J" target="_blank">pdf</a>,
            <a
              href="https://slideslive.com/38954089/ssd-a-unified-framework-for-selfsupervised-outlier-detection?ref=search">slides</a>).
          </div>
        </div>
        <div class="flex-container">
          <div>01/2021</div>
          <div class="news-text">
            Paper on PatchGuard accepted at
            <a href="https://www.usenix.org/conference/usenixsecurity21">USENIX Security</a>
            2021 (<a href="https://www.usenix.org/system/files/sec21fall-xiang.pdf">pdf</a>).
          </div>
        </div>
        <div class="flex-container">
          <div>10/2020</div>
          <div class="news-text">
            Releasing
            <a href="https://robustbench.github.io" target="_blank">RobustBench</a>, a standardized benchmark for
            adversarial robustness.
          </div>
        </div>
        <div class="flex-container">
          <div>10/2020</div>
          <div class="news-text">
            Work on fast-convergent federated learning to appear in
            <a href="https://www.comsoc.org/publications/journals/ieee-jsac">IEEE JSAC</a>
            (<a href="https://arxiv.org/abs/2007.13137">arxiv</a>).
          </div>
        </div>
        <div class="flex-container">
          <div>09/2020</div>
          <div class="news-text">
            Paper on prning robust networks (Hydra) accepted at
            <a href="https://neurips.cc/">NeurIPS 2020</a>. (<a href="https://vsehwag.github.io/hydra/">webpage</a>).
          </div>
        </div>
        <div class="flex-container">
          <div>07/2020</div>
          <div class="news-text">
            Paper on background check of deep learning - ICML OOL workshop (<a
              href="https://arxiv.org/pdf/2006.14077.pdf">pdf</a>,
            <a href="https://oolworkshop.github.io/program/ool_26.html">video</a>).
          </div>
        </div>
        <div class="flex-container">
          <div>07/2020</div>
          <div class="news-text">
            Work on separability of self-supervised representations, and another
            one on critical evaluation of open-world meachine learning, accepted
            at ICML UDL workshop.
          </div>
        </div>
        <div class="flex-container">
          <div>06/2020</div>
          <div class="news-text">
            Volunteered as junior mentor at
            <a href="https://researchcomputing.princeton.edu/events/princeton-olcf-nvidia-gpu-hackathon">Princeton-OLCF-NVIDIA
              GPU Hackathon.</a>
          </div>
        </div>
        <div class="flex-container">
          <div>05/2020</div>
          <div class="news-text">
            Releasing PatchGuard, a provable defense against adversarial patches
            (<a href="https://arxiv.org/pdf/2005.10884.pdf">Pdf</a>,
            <a href="https://github.com/inspire-group/PatchGuard">Code</a>).
          </div>
        </div>
        <div class="flex-container">
          <div>04/2020</div>
          <div class="news-text">
            Work on pruning robust networks accepted at
            <a href="https://trustworthyiclr20.github.io/" target="_blank">ICLR TTML workshop</a>
            (<a
              href="https://docs.google.com/presentation/d/1yLSnvUR5MFhv-Dp2yuQEF1QuFNffTSomUGuiZsZJmbY/edit?usp=sharing">slides</a>,
            <a
              href="https://slideslive.com/38926541/on-pruning-adversarially-robust-neural-networks?ref=account-folder-46630-folders">video</a>).
          </div>
        </div>
        <div class="flex-container">
          <div>01/2020</div>
          <div class="news-text">
            Taught a mini-course on adversarial attacks & defenses in
            Winterssion 2020 (<a
              href="https://docs.google.com/presentation/d/1bs7xMYndjUshWkgLppmpnle_ZWkVTA7QoOfJ79nG-Ko/edit?usp=sharing">Slides</a>,
            <a
              href="https://colab.research.google.com/drive/1Pyn8zgZUlBKz18kSL0vO0ojBE3AnVpl6?usp=sharing">Colab-notebook</a>).
          </div>
        </div>
        <!-- <div class="flex-container">
          <div>11/2019</div>
          <div class="news-text">
            Will present our paper on robust open-world machine learning at
            <a href="https://aisec.cc/">AISec 2019</a> (<a
              href="https://docs.google.com/presentation/d/12NQfyzcztr00gjicu0-BzROV178_fSJNTXMraoCspvw/edit?usp=sharing"
              >Slides</a
            >).
          </div>
        </div> -->
        <div class="flex-container">
          <div>09/2019</div>
          <div class="news-text">
            Finished amazing suumer research internship at Microsoft Research,
            Redmond.
          </div>
        </div>
        <div class="flex-container">
          <div>08/2019</div>
          <div class="news-text">
            Paper on robust open-world machine learning accepted at
            <a href="https://aisec.cc/">AISec 2019</a> (<a
              href="https://docs.google.com/presentation/d/12NQfyzcztr00gjicu0-BzROV178_fSJNTXMraoCspvw/edit?usp=sharing">Slides</a>).
          </div>
        </div>
        <div class="flex-container">
          <div>05/2019</div>
          <div class="news-text">
            Won
            <a href="https://www.qualcomm.com/invention/research/university-relations/innovation-fellowship/winners">Qualcomm
              Innovation Fellowship 2019</a>.
          </div>
        </div>
        <!-- <div class="flex-container">
          <div>08/2020</div>
          <div class="news-text">Add news text here.</div>
        </div> -->
      </div>
      <div class="news-twitter">
        <a class="twitter-timeline" data-lang="en" data-width="350" data-height="380" data-dnt="true"
          data-chrome="transparent" href="https://twitter.com/VSehwag_?ref_src=twsrc%5Etfw">Tweets by VSehwag_</a>
        <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
      </div>
    </div>
  </div>

  <div class="project-divider">
    <hr />
  </div>

  <!-- Publications: The major section in the middle of website-->
  <div class="publications container" id="pubs">
    <p class="section-heading">Publications</p>
    <!-- Create a copy of pubs-box for a new entry and pubs-section for a group of entries-->
    <div class="pubs-box key-pubs">
      <div class="pubs-data">
        <p class="title">
          Extracting Training Data from Diffusion Models
        </p>
        <p class="authors">
          Nicholas Carlini, Jamie Hayes, Milad Nasr, Matthew Jagielski, <em>Vikash Sehwag</em>, Florian Tram√®r, Borja
          Balle, Daphne Ippolito, Eric Wallace
        </p>
        <p class="venue">Arxiv 2023</p>
        <p class="links">
          <span><a href="https://arxiv.org/abs/2301.13188" target="_blank">pdf</a></span> / <span><a
              href="https://twitter.com/Eric_Wallace_/status/1620449934863642624?s=20"
              target="_blank">twitter</a></span>
        </p>

        <p class="summary">
          We show that modern diffusion models, such as Stable-diffusion and ImageN, memorize certain training images,
          which can be extracted by an adversary during sampling.
        </p>
      </div>
      <div class="pubs-image">
        <img src="./projects/memorize/demo.png" />
      </div>
    </div>

    <div class="pubs-box">
      <div class="pubs-data">
        <p class="title">
          A Light Recipe to Train Robust Vision Transformers
        </p>
        <p class="authors">
          Edoardo Debenedetti, <em>Vikash Sehwag</em>, Prateek Mittal
        </p>
        <p class="venue">SaTML 2023</p>
        <p class="links">
          <span><a href="https://arxiv.org/abs/2209.07399" target="_blank">pdf</a></span> / <span><a
              href="https://twitter.com/edoardo_debe/status/1575489807400083457?s=20" target="_blank">twitter</a></span>
        </p>

        <p class="summary">
          Contrary to the conventional wisdom of using heavy data augmentation in ViTs, we show that a lighter data
          augmentation
          (along with other bag-of-tricks) achieves state-of-the-art performance with ViTs adversarial training.
        </p>
      </div>
      <div class="pubs-image">
        <img src="./projects/lightVits/demo.png" />
      </div>
    </div>


    <div class="pubs-box key-pubs">
      <div class="pubs-data">
        <p class="title">
          Generating High Fidelity Data from Low-density Regions using Diffusion
          Models
        </p>
        <p class="authors">
          <em>Vikash Sehwag</em>, Caner Hazirbas, Albert Gordo, Firat Ozgenel,
          Cristian Canton Ferrer
        </p>
        <p class="venue">CVPR 2022</p>
        <p class="links">
          <span><a href="https://arxiv.org/abs/2203.17260" target="_blank">pdf</a></span>
        </p>

        <p class="summary">
          We improve the sampling process of diffusion models to generate high
          fidelity hard, i.e., from low-density regions, synthetic images.
        </p>
      </div>
      <div class="pubs-image">
        <img src="./projects/ab_sampling/samples.png" />
      </div>
    </div>

    <div class="pubs-box">
      <div class="pubs-data">
        <p class="title">
          Understanding Robust Learning through the Lens of Representation Similarities
        </p>
        <p class="authors">
          Christian Cianfarani, Arjun Nitin Bhagoji, <em>Vikash Sehwag</em>, Ben Y. Zhao, Prateek Mittal, Haitao Zheng
        </p>
        <p class="venue">NeurIPS 2022</p>
        <p class="links">
          <span><a href="https://arxiv.org/abs/2206.09868" target="_blank">pdf</a></span>
        </p>

        <p class="summary">
          Using representation similarity metrics, such as CKA, we demonstrate multiple interesting characteristics of
          adversarially robust networks compared to non-robust networks.
        </p>
      </div>
      <div class="pubs-image">
        <img src="./projects/cka/demo.png" />
      </div>
    </div>

    <div class="pubs-box key-pubs">
      <div class="pubs-data">
        <p class="title">
          Robust Learning Meets Generative Models: Can Proxy Distributions
          Improve Adversarial Robustness?
        </p>
        <p class="authors">
          <em>Vikash Sehwag</em>, Saeed Mahloujifar, Tinashe Handina, Sihui Dai,
          Chong Xiang, Mung Chiang, Prateek Mittal
        </p>
        <p class="venue">ICLR 2022</p>
        <p class="links">
          <span><a href="https://vsehwag.github.io/blog/2022/4/synthetic_data_in_ml.html"
              target="_blank">Blog</a></span>
          /
          <span><a href="https://arxiv.org/abs/2104.09425" target="_blank">Pdf</a></span>
          /
          <span><a href="https://iclr.cc/virtual/2022/poster/6374" target="_blank">Video</a></span>
          /
          <span><a href="https://iclr.cc/virtual/2022/poster/6374" target="_blank">Slides</a></span>
        </p>

        <p class="summary">
          We show that synthetic data from diffusion model provides a termendous
          boost in generalization performance of robust training.
        </p>
      </div>
      <div class="pubs-image">
        <img style="padding-left: 8px; padding-right: 3px" src="./projects/proxy/generative_learning_2.png" />
      </div>
    </div>

    <div class="pubs-box">
      <div class="pubs-data">
        <p class="title">
          Lower Bounds on Cross-Entropy Loss in the Presence of Test-time
          Adversaries
        </p>
        <p class="authors">
          Arjun Nitin Bhagoji, Daniel Cullina, <em>Vikash Sehwag</em>, Prateek
          Mittal
        </p>
        <p class="venue">ICML 2021</p>
        <p class="links">
          <span><a href="https://arxiv.org/abs/2203.17260" target="_blank">Pdf</a></span>
          /
          <span><a
              href="https://slideslive.com/38959167/lower-bounds-on-crossentropy-loss-in-the-presence-of-testtime-adversaries?ref=speaker-18989"
              target="_blank">Video</a></span>
          /
          <span><a
              href="https://slideslive.com/38959167/lower-bounds-on-crossentropy-loss-in-the-presence-of-testtime-adversaries?ref=speaker-18989"
              target="_blank">Slides</a></span>
          /
          <span><a href="https://arjunbhagoji.github.io/files/poster_icml_2021.pdf" target="_blank">Poster</a></span>
        </p>

        <p class="summary">
          We provide lower-bounds on cross-entropy loss in persence of
          adversarial attacks on basic vision datasets.
        </p>
      </div>
      <div class="pubs-image">
        <img src="./projects/ce_bounds/bounds_icml21.png" />
      </div>
    </div>

    <div class="pubs-box">
      <div class="pubs-data">
        <p class="title">
          SSD: A Unified Framework for Self-Supervised outlier detection
        </p>
        <p class="authors">
          <em>Vikash Sehwag</em>, Mung Chiang, Prateek Mittal
        </p>
        <p class="venue">
          ICLR 2021, Short version accepted at
          <a href="https://sslneuips20.github.io/" target="_blank">NeurIPS SSL</a>
          workshop, 2020
        </p>
        <p class="links">
          <span><a href="./projects/soon.html" target="_blank">Project-page</a></span>
          /
          <span><a href="https://drive.google.com/file/d/1GVb7UtVZKDvb6sHZ9dSlycnzEDnL7E1r/view?usp=sharing"
              target="_blank">Pdf</a></span>
        </p>

        <p class="summary">
          Using <em>only</em> unlabeled data, we develop a highly succesful
          framework to detect outliers or out-of-distribution samples.
        </p>
      </div>
      <div class="pubs-image">
        <img src="./projects/ssd/overview.png" />
      </div>
    </div>

    <div class="pub-divider">
      <hr />
    </div>

    <div class="pubs-box key-pubs">
      <div class="pubs-data">
        <p class="title">
          RobustBench: A Standardized Adversarial Robustness Benchmark
        </p>
        <p class="authors">
          Francesco Croce, Maksym Andriushchenko, <em>Vikash Sehwag</em>, <br />
          Nicolas Flammarion, Mung Chiang, Prateek Mittal, Matthias Hein
        </p>
        <p class="venue">NeurIPS, 2021</p>
        <p class="links">
          <span><a href="https://robustbench.github.io/" target="_blank">Project-page</a></span>
          /
          <span><a href="https://arxiv.org/abs/2010.09670" target="_blank">Pdf</a></span>
          /
          <span><a href="https://github.com/RobustBench/robustbench" target="_blank">Code</a></span>
        </p>

        <p class="summary">
          We provide a leaderboard to track progress + a library for unified
          access to SOTA defenses against adversarial examples.
        </p>
      </div>
      <div class="pubs-image">
        <img src="./projects/robustbench/logo.png" />
      </div>
    </div>

    <div class="pub-divider">
      <hr />
    </div>

    <div class="pubs-box">
      <div class="pubs-data">
        <p class="title">
          Time for a Background Check! Uncovering the impact of Background
          Features on Deep Neural Networks
        </p>
        <p class="authors">
          <em>Vikash Sehwag</em>, Rajvardhan Oak, Mung Chiang, Prateek Mittal
        </p>
        <p class="venue">ICML workshop on Object-Oriented Learning, 2020</p>
        <p class="links">
          <span><a href="./projects/background_check/background_check.html" target="_blank">Project-page</a></span>
          /
          <span><a href="https://arxiv.org/pdf/2006.14077.pdf" target="_blank">Pdf</a></span>
          /
          <span><a href="./projects/background_check/background_check.html#bibtex" target="_blank">Bibtex</a></span>
          /
          <span><a
              href="https://docs.google.com/presentation/d/1dsFVA406PhxfHoBDkDJY2lzJRXGkClFpq0Tb4YTLg_o/edit?usp=sharing"
              target="_blank">Slides</a></span>
          /
          <span><a href="https://oolworkshop.github.io/program/ool_26.html" target="_blank">Video</a></span>
        </p>

        <p class="summary">
          We investigate background invariance and influence over 32 deep neural
          networks on ImageNet dataset.
        </p>
      </div>
      <div class="pubs-image">
        <img src="./projects/background_check/invariance.png" />
      </div>
    </div>

    <div class="pub-divider">
      <hr />
    </div>

    <div class="pubs-box">
      <div class="pubs-data">
        <p class="title">On Separability of Self-Supervised Representations</p>
        <p class="authors">
          <em>Vikash Sehwag</em>, Mung Chiang, Prateek Mittal
        </p>
        <p class="venue">
          ICML workshop on Uncertainty & Robustness in Deep Learning, 2020
        </p>
        <p class="links">
          <span><a href="http://www.gatsby.ucl.ac.uk/~balaji/udl2020/accepted-papers/UDL2020-paper-131.pdf"
              target="_blank">Pdf</a></span>
          /
          <span><a href="./projects/ssl_margin/bibtex.html" target="_blank">Bibtex</a></span>
          /
          <span><a
              href="https://docs.google.com/presentation/d/119v5iI1FxLwEEAav6Yu5kvvF4sx79iSLgJom-c3grOI/edit?usp=sharing"
              target="_blank">Slides</a></span>
        </p>

        <p class="summary">
          We compare the representations learned by several self-supervised
          methods with supervised networks.
        </p>
      </div>
      <div class="pubs-image">
        <img src="./projects/ssl_margin/ssl_margin.png" />
      </div>
    </div>

    <div class="pubs-box key-pubs">
      <div class="pubs-data">
        <p class="title">HYDRA: Pruning Adversarially Robust Neural Networks</p>
        <p class="authors">
          <em>Vikash Sehwag</em>, Shiqi Wang, Prateek Mittal, Suman Jana
        </p>
        <p class="venue">
          NeurIPS 2020,
          <a href="" target="_blank">Short paper</a> in ICLR workshop on
          Trustworthy Machine Learning, 2020
        </p>
        <p class="links">
          <span><a href="https://vsehwag.github.io/hydra" target="_blank">Project-page</a></span>
          /
          <span><a href="https://arxiv.org/abs/2002.10509" target="_blank">Pdf</a></span>
          /
          <span><a href="./projects/hydra/hydra.html#bibtex" target="_blank">Bibtex</a></span>
          /
          <span><a href="https://github.com/inspire-group/compactness-robustness" target="_blank">Code</a></span>
          /
          <span><a
              href="https://docs.google.com/presentation/d/1yLSnvUR5MFhv-Dp2yuQEF1QuFNffTSomUGuiZsZJmbY/edit?usp=sharing"
              target="_blank">Slides</a></span>
          /
          <span><a
              href="https://slideslive.com/38926541/on-pruning-adversarially-robust-neural-networks?ref=account-folder-46630-folders"
              target="_blank">Video</a></span>
        </p>

        <p class="summary">
          We achieve state-of-the-art accuracy and robustness for pruned
          networks (pruning up to 100x).
        </p>
      </div>
      <div class="pubs-image"><img src="./projects/hydra/hydra.png" /></div>
    </div>

    <div class="pub-divider">
      <hr />
    </div>

    <div class="pubs-box">
      <div class="pubs-data">
        <p class="title">
          PatchGuard: Provable Defense against Adversarial Patches Using Masks
          on Small Receptive Fields
        </p>
        <p class="authors">
          Chong Xiang, Arjun Nitin Bhagoji, <em>Vikash Sehwag</em>, Prateek
          Mittal
        </p>
        <p class="venue">Arxiv, 2020</p>
        <p class="links">
          <span><a href="./projects/soon.html" target="_blank">Project-page</a></span>
          /
          <span><a href="https://arxiv.org/pdf/2005.10884.pdf" target="_blank">Pdf</a></span>
          /
          <span><a href="./projects/patchguard/bibtex.html" target="_blank">Bibtex</a></span>
        </p>

        <p class="summary">
          A general defense framework to acheive provable robustness against
          adversrial patches.
        </p>
      </div>
      <div class="pubs-image">
        <img src="./projects/patchguard/demo.png" />
      </div>
    </div>

    <div class="pub-divider">
      <hr />
    </div>

    <div class="pubs-box">
      <div class="pubs-data">
        <p class="title">Fast-Convergent Federated Learning</p>
        <p class="authors">
          Hung T. Nguyen, <em>Vikash Sehwag</em>, Seyyedali Hosseinalipour,
          Christopher G. Brinton, Mung Chiang, H. Vincent Poor
        </p>
        <p class="venue">
          To appear in IEEE Journal on Selected Areas in Communications (J-SAC)
          - Series on Machine Learning for Communications and Networks
        </p>
        <p class="links">
          <span><a href="./projects/soon.html" target="_blank">Project-page</a></span>
          /
          <span><a href="https://arxiv.org/pdf/2006.14077.pdf" target="_blank">Pdf</a></span>
          /
          <span><a href="./projects/folb/bibtex.html" target="_blank">Bibtex</a></span>
        </p>

        <p class="summary">
          We proposed a fast-convergent federated learning algorithm, called
          FOLB, which improves convergence speed by an intelligent sampling of
          devices in each round.
        </p>
      </div>
      <div class="pubs-image">
        <img src="./projects/folb/system.png" />
      </div>
    </div>

    <div class="pubs-box">
      <div class="pubs-data">
        <p class="title">
          A Critical Evaluation of Open-World Machine Learning
        </p>
        <p class="authors">
          Liwei Song, <em>Vikash Sehwag</em>, Arjun Nitin Bhagoji, Prateek
          Mittal
        </p>
        <p class="venue">
          ICML Workshop on Uncertainty & Robustness in Deep Learning , 2020
        </p>
        <p class="links">
          <span><a href="https://arxiv.org/pdf/2007.04391.pdf" target="_blank">Pdf</a></span>
          /
          <span><a href="./projects/ood_udl/bibtex.html" target="_blank">Bibtex</a></span>
          /
          <span><a href="https://github.com/inspire-group/OOD-Attacks" target="_blank">Code</a></span>
        </p>

        <p class="summary">
          We discover a conflict between the objective of open-world machine
          learning and adversarial robustness.
        </p>
      </div>
      <div class="pubs-image"><img src="./projects/ood_udl/tsne.png" /></div>
    </div>

    <div class="pubs-box">
      <div class="pubs-data">
        <p class="title">
          Analyzing the Robustness of Open-World Machine Learning
        </p>
        <p class="authors">
          <em>Vikash Sehwag</em>, Arjun Nitin Bhagoji, Liwei Song, Chawin
          Sitawarin, Daniel Cullina, Mung Chiang, Prateek Mittal
        </p>
        <p class="venue">
          ACM Workshop on Artificial Intelligence and Security (AISec), 2019
        </p>
        <p class="links">
          <span><a href="https://dl.acm.org/doi/pdf/10.1145/3338501.3357372" target="_blank">Pdf</a></span>
          /
          <span><a href="./projects/ood_aisec/bibtex.html" target="_blank">Bibtex</a></span>
          /
          <span><a href="https://github.com/inspire-group/OOD-Attacks" target="_blank">Code</a></span>
          /
          <span><a
              href="https://docs.google.com/presentation/d/12NQfyzcztr00gjicu0-BzROV178_fSJNTXMraoCspvw/edit?usp=sharing"
              target="_blank">Slides</a></span>
        </p>

        <p class="summary">
          We demonstrate the vulnerability of open-world ML to adversarial
          examples and proposed a defense.
        </p>
      </div>

      <div class="pubs-image">
        <img src="./projects/ood_aisec/outline.png" />
      </div>
    </div>
    <!-- <div class="pubs-box"></div> -->
    <!-- <div class="pubs-box"></div> -->

    <!-- <div class="pubs-section">
      <p class="theme">
        <span id="theme-text">Theme:</span> Robust Open-world machine learning:
        Making neural networks learn what they <em>do and don't know</em>, even
        in presence of an adversary!
      </p>

      <div class="pubs-section-box">
        <p class="bullet">&#9758;</p>
        <div class="pubs-data">
          <p class="title">
            A Critical Evaluation of Open-World Machine Learning
          </p>
          <p class="authors">
            Liwei Song, <em>Vikash Sehwag</em>, Arjun Nitin Bhagoji, Prateek
            Mittal
          </p>
          <p class="venue">
            ICML Workshop on Uncertainty & Robustness in Deep Learning , 2020
          </p>
          <p class="links">
            <span
              ><a href="https://arxiv.org/pdf/2007.04391.pdf" target="_blank"
                >Pdf</a
              ></span
            >
            /
            <span
              ><a href="./projects/ood_udl/bibtex.html" target="_blank"
                >Bibtex</a
              ></span
            >
            /
            <span
              ><a
                href="https://github.com/inspire-group/OOD-Attacks"
                target="_blank"
                >Code</a
              ></span
            >
          </p>

          <p class="summary">
            We discover a conflict between the objective of open-world machine
            learning and adversarial robustness.
          </p>
        </div>
        <div class="pubs-image"><img src="./projects/ood_udl/tsne.png" /></div>
      </div>

      <div class="pubs-section-box key-pubs">
        <p class="bullet">&#9758;</p>
        <div class="pubs-data">
          <p class="title">
            Analyzing the Robustness of Open-World Machine Learning
          </p>
          <p class="authors">
            <em>Vikash Sehwag</em>, Arjun Nitin Bhagoji, Liwei Song, Chawin
            Sitawarin, Daniel Cullina, Mung Chiang, Prateek Mittal
          </p>
          <p class="venue">
            ACM Workshop on Artificial Intelligence and Security
            (<strong>AISec</strong>), 2019
          </p>
          <p class="links">
            <span
              ><a
                href="https://dl.acm.org/doi/pdf/10.1145/3338501.3357372"
                target="_blank"
                >Pdf</a
              ></span
            >
            /
            <span
              ><a href="./projects/ood_aisec/bibtex.html" target="_blank"
                >Bibtex</a
              ></span
            >
            /
            <span
              ><a
                href="https://github.com/inspire-group/OOD-Attacks"
                target="_blank"
                >Code</a
              ></span
            >
            /
            <span
              ><a
                href="https://docs.google.com/presentation/d/12NQfyzcztr00gjicu0-BzROV178_fSJNTXMraoCspvw/edit?usp=sharing"
                target="_blank"
                >Slides</a
              ></span
            >
          </p>

          <p class="summary">
            We demonstrate the vulnerability of open-world ML to adversarial
            examples and proposed a defense.
          </p>
        </div>

        <div class="pubs-image">
          <img src="./projects/ood_aisec/outline.png" />
        </div>
      </div>
    </div> -->

    <div class="pub-divider">
      <hr />
    </div>

    <div class="pubs-section work-in-progress">
      <p class="theme">Research Work in Undergraduate</p>

      <div class="pubs-section-box">
        <p class="bullet-small">&#10143;</p>
        <div class="pubs-data">
          A Parallel Stochastic Number Generator With Bit Permutation Networks
          with N. Prasad and Indrajit Chakrabarti
          <p class="authors">
            IEEE Transactions on Circuits and Systems II: Express Briefs, 2017
            (<a href="https://ieeexplore.ieee.org/abstract/document/7933972" target="_blank">Pdf</a>)
          </p>
        </div>
      </div>
      <div class="pubs-section-box">
        <p class="bullet-small">&#10143;</p>
        <div class="pubs-data">
          Variation Aware Performance Analysis of TFETs for Low-Voltage
          Computing with Saurav Maji and Mrigank Sharad
          <p class="authors">
            IEEE International Symposium on Nanoelectronic and Information
            Systems (iNIS), 2016 (<a href="https://ieeexplore.ieee.org/document/7829530" target="_blank">Pdf</a>)
          </p>
        </div>
      </div>
      <div class="pubs-section-box">
        <p class="bullet-small">&#10143;</p>
        <div class="pubs-data">
          TV-PUF: a fast lightweight analog physical unclonable function with
          Tanujay Saha
          <p class="authors">
            IEEE International Symposium on Nanoelectronic and Information
            Systems (iNIS), 2016 (<a href="https://ieeexplore.ieee.org/document/7829547" target="_blank">Pdf</a>)
          </p>
        </div>
      </div>
      <div class="pubs-section-box">
        <p class="bullet-small">&#10143;</p>
        <div class="pubs-data">
          A Study of Stochastic SIS Disease Spreading on Random Graphs with
          Wasiur R. KhudaBukhsh and Heinz Koeppl, 2016 (<a
            href="https://drive.google.com/file/d/1s73reSAd5YrF6_uMkChskbYI9Ijc5xii/view?usp=sharing"
            target="_blank">Pdf</a>)
        </div>
      </div>
    </div>

    <div class="full-project-divider">
      <hr />
    </div>

    <div class="news container" id="teaching">
      <p class="section-heading">Academic Services</p>
      <div class="pubs-section work-in-progress">
        <p class="theme">Teaching and Mentoring</p>

        <div class="pubs-section-box">
          <p class="bullet-small">&#10143;</p>
          <div class="pubs-data">
            Taught a mini-course on adversarial attacks & defenses (Winterssion
            2020)
          </div>
        </div>
        <div class="pubs-section-box">
          <p class="bullet-small">&#10143;</p>
          <div class="pubs-data">
            Teaching assistant for ELE 535: Machine Learning and Pattern
            Recognition (Fall 2019)
          </div>
        </div>
        <div class="pubs-section-box">
          <p class="bullet-small">&#10143;</p>
          <div class="pubs-data">
            Mentoring Princeton undergraduates for their senior independent
            research work <br />
            Tinashe Handina (B.S.E., Electrical Engineering 2021); Matteo Russo
            (B.S.E., Computer Science 2020)
          </div>
        </div>

        <p class="theme">Other Services</p>

        <div class="pubs-section-box">
          <p class="bullet-small">&#10143;</p>
          <div class="pubs-data">
            One of the core maintainers of Adversarial Robustness Benchmark (<a href="https://robustbench.github.io/"
              target="_blank">robustbench.github.io</a>)
          </div>
        </div>
        <div class="pubs-section-box">
          <p class="bullet-small">&#10143;</p>
          <div class="pubs-data">
            Volunteered as junior mentor at Princeton-OLCF-NVIDIA GPU Hackathon
            (June 2020)
          </div>
        </div>
        <div class="pubs-section-box">
          <p class="bullet-small">&#10143;</p>
          <div class="pubs-data">
            Reviewer for ACM Transactions on Privacy and Security (TOPS), PLOS
            One
          </div>
        </div>
        <div class="pubs-section-box">
          <p class="bullet-small">&#10143;</p>
          <div class="pubs-data">
            Sub-reviewer for USENIX Security 2018, 2019
          </div>
        </div>
      </div>
    </div>
  </div>

  <div class="full-project-divider">
    <hr />
  </div>

  <footer>
    <small>&copy; 2022, Vikash Sehwag &emsp; &emsp; &emsp; Feel free to use the
      <a href="https://github.com/VSehwag/vsehwag.github.io" , target="_blank">source code.</a>
    </small>
  </footer>
</body>